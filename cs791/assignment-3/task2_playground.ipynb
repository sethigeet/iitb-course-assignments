{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96ec7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3eab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# HF_TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74b32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553c04ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.06s/it]\n",
      "/users/extusr/sethigeet/assignment-3/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, token=None)\n",
    "model.eval()\n",
    "model.to(DEVICE) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eec031e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_PROMPT = \"The wind whispered through old ruins\"\n",
    "INSTRUCTION_PROMPT = \"Continue the story.\"\n",
    "PROMPT = f\"{PREFIX_PROMPT}\\n\\n{INSTRUCTION_PROMPT}.\\n\"\n",
    "MAX_NEW_TOKENS = 20\n",
    "K = 8\n",
    "k = 10\n",
    "beta = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7509ceb",
   "metadata": {},
   "source": [
    "## Sequential Monte Carlo Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ad52a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_counts_and_reward\n",
    "\n",
    "reward_calc = load_counts_and_reward(\"./tinystories_ngrams\")\n",
    "\n",
    "def reward_sum_pos_ids(ids) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        reward_calc: FastRewardCalculator (token_lm.logp available).\n",
    "        tokenizer: for ids→tokens conversion.\n",
    "        ids: current full context ids (prompt + generated so far).\n",
    "\n",
    "    Returns:\n",
    "        float ΔR_t ≥ 0.\n",
    "    \"\"\"\n",
    "    if len(ids) < 3:\n",
    "        return 0.0\n",
    "\n",
    "    tokens = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "    reward = reward_calc.calculate_reward_tokens(\n",
    "        tokens.strip().split(\" \"), normalize=True\n",
    "    )\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891ca87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1190, 0.1291, 0.1190, 0.1291, 0.1190, 0.1190, 0.1366, 0.1291])\n",
      "tensor([5, 1, 5, 4, 0, 7, 3, 0], device='cuda:0')\n",
      "tensor([0.1236, 0.1167, 0.1236, 0.1236, 0.1236, 0.1255, 0.1399, 0.1236])\n",
      "tensor([4, 4, 3, 5, 1, 4, 0, 0], device='cuda:0')\n",
      "tensor([0.1215, 0.1215, 0.1215, 0.1417, 0.1294, 0.1215, 0.1215, 0.1215])\n",
      "tensor([5, 4, 5, 0, 2, 0, 5, 2], device='cuda:0')\n",
      "tensor([0.0957, 0.3298, 0.0957, 0.0957, 0.0957, 0.0957, 0.0957, 0.0957])\n",
      "tensor([1, 1, 2, 2, 6, 1, 2, 0], device='cuda:0')\n",
      "tensor([0.1115, 0.1115, 0.1303, 0.1303, 0.1303, 0.1115, 0.1442, 0.1303])\n",
      "tensor([5, 0, 7, 0, 0, 2, 2, 7], device='cuda:0')\n",
      "tensor([0.1479, 0.1479, 0.1374, 0.0069, 0.1479, 0.1374, 0.1374, 0.1374])\n",
      "tensor([4, 0, 4, 0, 1, 4, 4, 2], device='cuda:0')\n",
      "tensor([0.1240, 0.1278, 0.1240, 0.1327, 0.1278, 0.1240, 0.1327, 0.1071])\n",
      "tensor([4, 5, 6, 6, 0, 1, 4, 6], device='cuda:0')\n",
      "tensor([0.1238, 0.1249, 0.1262, 0.1262, 0.1249, 0.1238, 0.1238, 0.1262])\n",
      "tensor([3, 2, 7, 0, 7, 4, 3, 1], device='cuda:0')\n",
      "tensor([0.1308, 0.1308, 0.0985, 0.1378, 0.0985, 0.1365, 0.1308, 0.1365])\n",
      "tensor([1, 7, 2, 1, 6, 3, 1, 2], device='cuda:0')\n",
      "tensor([0.1567, 0.1076, 0.1068, 0.1503, 0.1363, 0.0958, 0.1398, 0.1068])\n",
      "tensor([7, 4, 6, 7, 0, 3, 1, 6], device='cuda:0')\n",
      "tensor([0.1705, 0.1979, 0.1134, 0.1705, 0.1148, 0.1034, 0.0162, 0.1134])\n",
      "tensor([5, 7, 3, 0, 7, 1, 2, 1], device='cuda:0')\n",
      "tensor([0.1652, 0.1557, 0.0179, 0.0179, 0.1608, 0.1534, 0.1557, 0.1735])\n",
      "tensor([1, 5, 7, 5, 0, 6, 2, 0], device='cuda:0')\n",
      "tensor([0.1403, 0.1323, 0.1080, 0.1323, 0.1000, 0.1403, 0.1466, 0.1000])\n",
      "tensor([5, 1, 1, 2, 4, 0, 6, 4], device='cuda:0')\n",
      "tensor([0.0367, 0.1728, 0.1728, 0.1623, 0.1620, 0.0367, 0.0946, 0.1620])\n",
      "tensor([6, 1, 1, 4, 1, 7, 3, 1], device='cuda:0')\n",
      "tensor([0.0793, 0.0369, 0.0369, 0.2517, 0.0369, 0.2305, 0.2589, 0.0689])\n",
      "tensor([5, 1, 6, 3, 5, 0, 4, 6], device='cuda:0')\n",
      "tensor([0.1521, 0.1727, 0.0435, 0.0758, 0.1307, 0.0411, 0.1727, 0.2114])\n",
      "tensor([0, 3, 4, 1, 1, 6, 3, 2], device='cuda:0')\n",
      "tensor([0.1970, 0.0936, 0.1809, 0.1330, 0.1330, 0.1330, 0.0704, 0.0591])\n",
      "tensor([5, 3, 1, 3, 5, 5, 1, 0], device='cuda:0')\n",
      "tensor([0.1158, 0.1158, 0.0794, 0.1158, 0.1158, 0.1158, 0.0794, 0.2620])\n",
      "tensor([6, 6, 6, 7, 7, 4, 3, 5], device='cuda:0')\n",
      "tensor([0.2381, 0.2381, 0.1842, 0.0812, 0.0812, 0.0591, 0.0591, 0.0591])\n",
      "tensor([2, 5, 5, 3, 3, 5, 0, 2], device='cuda:0')\n",
      "tensor([0.0969, 0.2281, 0.2281, 0.0317, 0.0317, 0.2281, 0.0585, 0.0969])\n",
      "tensor([0, 6, 5, 1, 4, 5, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(PROMPT, return_tensors=\"pt\").to(model.device)\n",
    "input_tokens_size = input_ids.shape[1]\n",
    "input_ids = input_ids.repeat(K, 1)\n",
    "\n",
    "completed_ids = torch.zeros(K).to(model.device)\n",
    "\n",
    "# Define here to have access to the weights variable outside the loop\n",
    "weights = []\n",
    "normalized_weights = []\n",
    "\n",
    "for _ in range(MAX_NEW_TOKENS):\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits[:, -1, :]\n",
    "\n",
    "    # Get top-k logits and indices and convert to probabilities\n",
    "    top_k_logits, top_k_indices = torch.topk(logits, k, dim=-1)\n",
    "    probs = torch.softmax(top_k_logits, dim=-1)\n",
    "\n",
    "    # Sample from the top-k distribution\n",
    "    next_token_ids = []\n",
    "    weights = []\n",
    "    for i in range(K):\n",
    "        if completed_ids[i]:\n",
    "            next_token_ids.append(model.config.eos_token_id)\n",
    "            weights.append(1.0)\n",
    "            continue\n",
    "\n",
    "        sampled_idx = torch.multinomial(probs[i], 1)\n",
    "\n",
    "        next_token_id = top_k_indices[i, sampled_idx].item()\n",
    "        next_token_prob = top_k_logits[i, sampled_idx].item()\n",
    "        next_token_ids.append(next_token_id)\n",
    "\n",
    "        pi_t = math.exp(\n",
    "            beta * reward_sum_pos_ids(input_ids[i])\n",
    "        )\n",
    "        pi_t_1 = math.exp(\n",
    "            beta\n",
    "            * reward_sum_pos_ids(\n",
    "                torch.cat(\n",
    "                    [input_ids[i], torch.tensor([next_token_id]).to(model.device)]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        weight = pi_t / (pi_t_1 * next_token_prob)\n",
    "        weights.append(weight)\n",
    "\n",
    "    next_token_ids = torch.tensor(next_token_ids).to(model.device)\n",
    "    input_ids = torch.cat(\n",
    "        [\n",
    "            input_ids,\n",
    "            next_token_ids.unsqueeze(-1),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    total_weights = sum(weights)\n",
    "    normalized_weights = torch.tensor(weights) / total_weights\n",
    "\n",
    "    # Resample\n",
    "    resampled_indices = torch.multinomial(normalized_weights, K, replacement=True).to(input_ids.device)\n",
    "    print(normalized_weights)\n",
    "    print(resampled_indices)\n",
    "    input_ids = input_ids[resampled_indices]\n",
    "\n",
    "    # Stop if all sequences are completed\n",
    "    completed_ids = completed_ids.masked_fill(\n",
    "        next_token_ids == model.config.eos_token_id, 1\n",
    "    )\n",
    "    if completed_ids.all():\n",
    "        break\n",
    "\n",
    "gen_ids = input_ids[:, input_tokens_size:].tolist()\n",
    "\n",
    "samples = []\n",
    "for i in range(K):\n",
    "    samples.append(\n",
    "        {\n",
    "            \"text\": tokenizer.decode(gen_ids[i], skip_special_tokens=True),\n",
    "            \"weight\": weights[i],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715005a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'As I walked through the crumbling arches and weathered stones, I felt a strange energy coursing',\n",
       "  'weight': 0.05830518478831011},\n",
       " {'text': 'As I walked through the crumbling arches and weathered stones, I felt a strange energy emanating',\n",
       "  'weight': 0.1372190051489348},\n",
       " {'text': 'As I walked through the crumbling arches and crumbling stone, the wind whispered secrets in my ear.',\n",
       "  'weight': 0.1372190051489348},\n",
       " {'text': 'As I walked through the crumbling arches and crumbling stone, the wind whispered secrets in my ear.',\n",
       "  'weight': 0.01904768555878557},\n",
       " {'text': 'As I walked through the crumbling arches and weathered stones, I couldn’t shake the feeling that',\n",
       "  'weight': 0.01904768555878557},\n",
       " {'text': 'As I walked through the crumbling arches and crumbling stone, the wind whispered secrets in my ear.',\n",
       "  'weight': 0.1372190051489348},\n",
       " {'text': 'As I walked through the crumbling arches and crumbling stone, the wind whispered secrets in my ear.',\n",
       "  'weight': 0.03516313708236531},\n",
       " {'text': 'As I walked through the crumbling arches and weathered stones, I couldn’t shake the feeling that',\n",
       "  'weight': 0.05830518478831011}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
